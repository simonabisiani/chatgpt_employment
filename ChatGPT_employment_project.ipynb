{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLZPvyxhuzKT+qrvblG20a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simonabisiani/chatgpt_employment/blob/main/ChatGPT_employment_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT and employment project\n",
        "*Authors: Simona Bisiani, Al-Hussein Abutaleb*\n",
        "\n",
        "The purpose of this notebook is to perform and evaluate a text analysis of tweets relating to ChatGPT and employment. The project sits within research conducted at the Surrey Institute for Artificial Intelligence by Dr Eddy Zhu and Dr Erin Ling. \n",
        "\n",
        "The notebook includes the following sections:\n",
        "- data collection (this is not to be re-run, it's only included for transparency purposes)\n",
        "- summary statistics and characteristics of the data\n",
        "- topic modeling\n",
        "- sentiment analysis"
      ],
      "metadata": {
        "id": "AGLHX63XmHFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The necessary data for processing code in this notebook can be found at this [GitHub repository](https://github.com/simonabisiani/chatgpt_employment). We will use the code below to load the data in the notebook."
      ],
      "metadata": {
        "id": "xtUaLKOV6037"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING THE DATA\n",
        "!git clone https://github.com/simonabisiani/chatgpt_employment.git"
      ],
      "metadata": {
        "id": "53gvcuHf6yIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rpy2==3.5.1   # needed to run R code in colab; restart runtime after running this chunk"
      ],
      "metadata": {
        "id": "k1a2o9YWz80d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext rpy2.ipython\n",
        "\n",
        "# this command allows us to run both R and Python code throughout the notebook. \n",
        "#Whenever we need to run R code, we simply need to include %%R at the beginning of the code chunk"
      ],
      "metadata": {
        "id": "R2lf3DFHnxrd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data collection\n",
        "Upon recommendations from Dr Ling, we queried Twitter for tweets relating to search **chatgpt** *AND* any of the following words:\n",
        "**\"employment\", \"employability\", \"employer\",\"employee\", \"unemployment\",      \"unemployed\", \"job\", \"work\", \"skill\", \"taking over\", \"replace human\", \"performance\", \"concern\", \"insecurity\", \"fear\", \"threat\", \"opportunities\", \"training\",\"creation\", \"displacement\", \"occupation\", \"earning\",\"future demand\",\n",
        "\"education\", \"labour\", \"labor\", \"task\", \"industry\", \"workforce\", \"shortage\",\"collaboration\", \"collaborate\", \"human ai team\", \"team\", \"economic\", \"economy\"** \n",
        "\n",
        "On 24th February we collected, using the Twitter API and the R package *academictwitteR*, any tweets containing our query **between 30th November 2022 and 24th February 2023**. The data collection was only possible through an Academic Twitter API developer account, due to: the number of tweets wanted, and the possibility to search the full archive. With a standard developer account (e.g. Elevated), this would have not been possible.\n",
        "\n",
        "The code we wrote to collect the data is this:\n",
        "\n",
        "```\n",
        "chatgpt_full_collection <- data.frame()\n",
        "and <- \"chatgpt\"\n",
        "or <- c(\"employment\",\n",
        "        \"employability\",\n",
        "        \"employer\",\n",
        "        \"employee\",         \n",
        "        \"unemployment\",\n",
        "        \"unemployed\",\n",
        "        \"job\", \n",
        "        \"work\",\n",
        "        \"skill\",\n",
        "        \"taking over\",\n",
        "        \"replace human\",\n",
        "        \"performance\",\n",
        "        \"concern\",\n",
        "        \"insecurity\",\n",
        "        \"fear\",\n",
        "        \"threat\",\n",
        "        \"opportunities\",\n",
        "        \"training\",\n",
        "        \"creation\", \n",
        "        \"displacement\", \n",
        "        \"occupation\",\n",
        "        \"earning\", \n",
        "        \"future demand\",\n",
        "        \"education\",\n",
        "        \"labour\",\n",
        "        \"labor\", \n",
        "        \"task\", \n",
        "        \"industry\",\n",
        "        \"workforce\",\n",
        "        \"shortage\", \n",
        "        \"collaboration\", \n",
        "        \"collaborate\", \n",
        "        \"human ai team\",\n",
        "        \"team\",\n",
        "        \"economic\", \n",
        "        \"economy\")\n",
        "\n",
        "queries <- paste(and, or)\n",
        "\n",
        "for (i in queries) {\n",
        "  iteration_i <- get_all_tweets(\n",
        "    query = i,\n",
        "    start_tweets = \"2022-11-30T00:00:00Z\",\n",
        "    end_tweets = \"2023-02-24T00:00:00Z\",\n",
        "    n = Inf,\n",
        "    bearer_token = bearer_token, # NOTE! the bearer token is not included in this notebook, making this code chunk impossible to run unless in possession of a Twitter API Academic account\n",
        "    data_path = \"chatgpt_full_collection/\")\n",
        "  iteration_i$query <- i  \n",
        "  chatgpt_full_collection <- bind_rows(chatgpt_full_collection, iteration_i)}\n",
        "\n",
        "saveRDS(chatgpt_full_collection, \"chatgpt_full_collection.RDS\")\n",
        "data <- readRDS(\"chatgpt_full_collection.RDS\")\n",
        "tweets <- data %>% select(text, query, created_at, author_id)\n",
        "\n",
        "file <- toJSON(tweets)\n",
        "write(file, \"full_dataset_chatgpt.json\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "RjQK48tQoYYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is little knowledge on query formulation on Twitter. Our **assumption** was **that the singular form of the word** (or its canonical form) **would return** tweets containing **the plural form too**. However, using another function from the academictwitteR package, which allows us to check for the number of tweets resulting from a query without needing to download the data, we found out **this appears not to be true**.\n",
        "\n",
        "We ran the code below to obtain the number of tweets for each of the singular/plural pairs, and saved the data. Let's load the data in the notebook so we can visualise the differences in counts between singular/plural queries.\n",
        "\n",
        "```\n",
        "and <- \"chatgpt\"\n",
        "or <- c(\"employee\",\n",
        "        \"employees\", # post collection insertion\n",
        "        \"job\", \n",
        "        \"jobs\", # post collection insertion\n",
        "        \"skill\",\n",
        "        \"skills\", # post collection insertion\n",
        "        \"concern\",\n",
        "        \"concerns\", # post collection insertion\n",
        "        \"threat\",\n",
        "        \"threats\", # post collection insertion\n",
        "        \"occupation\", # captures occupations\n",
        "        \"occupations\", # post collection insertion\n",
        "        \"earning\", # captures earnings\n",
        "        \"earnings\", # post collection insertion\n",
        "        \"task\", # captures tasks\n",
        "        \"tasks\", # post collection insertion\n",
        "        \"team\", # NEW SUGGESTION (would also capture the above)\n",
        "        \"teams\") # post collection insertion\n",
        "\n",
        "queries <- paste(and, or)\n",
        "\n",
        "query_counts <- data.frame()\n",
        "for (i in queries) {\n",
        "  iteration_i <- count_all_tweets(i,\n",
        "                                  \"2022-11-30T00:00:00Z\",\n",
        "                                  \"2023-02-24T00:00:00Z\",\n",
        "                                  bearer_token,\n",
        "                                  n = 500)\n",
        "  iteration_i$query <- i  # Create a new column \"query\" and assign it the value of i\n",
        "  query_counts <- bind_rows(query_counts, iteration_i)}\n",
        "\n",
        "saveRDS(query_counts, \"query_counts.RDS\")\n",
        "```\n",
        "\n",
        "Let's now see what we can figure out from comparing singular/plural versions of the same word."
      ],
      "metadata": {
        "id": "NxyIyun_tgrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R \n",
        "\n",
        "library(tidyverse)\n",
        "\n",
        "query_counts <- read_csv(\"/content/chatgpt_employment/query_counts.csv\")\n",
        "\n",
        "library(RColorBrewer)\n",
        "\n",
        "# JOB VS JOBS\n",
        "p1 <- query_counts %>% \n",
        "  filter(str_detect(query, \"job\")) %>% \n",
        "ggplot(aes(x = as.Date(start), y = tweet_count, fill = query)) +\n",
        "  geom_bar(stat = \"identity\", alpha = 0.8, position = \"dodge\") +\n",
        "  scale_fill_brewer(palette = \"Set1\", name = \"Query\")+\n",
        "  theme_minimal()+\n",
        "  xlab(\"\")+\n",
        "  ylab(\"tweet count\") \n",
        "\n",
        "# SKILL VS SKILLS\n",
        "p2 <- query_counts %>% \n",
        "  filter(str_detect(query, \"skill\")) %>% \n",
        "  ggplot(aes(x = as.Date(start), y = tweet_count, fill = query)) +\n",
        "  geom_bar(stat = \"identity\", alpha = 0.8, position = \"dodge\") +\n",
        "  scale_fill_brewer(palette = \"Set1\", name = \"Query\")+\n",
        "  theme_minimal()+\n",
        "  xlab(\"\")+\n",
        "  ylab(\"tweet count\")\n",
        "\n",
        "# THREAT VS THREATS\n",
        "p3 <- query_counts %>% \n",
        "  filter(str_detect(query, \"threat\")) %>% \n",
        "  ggplot(aes(x = as.Date(start), y = tweet_count, fill = query)) +\n",
        "  geom_bar(stat = \"identity\", alpha = 0.8, position = \"dodge\") +\n",
        "  scale_fill_brewer(palette = \"Set1\", name = \"Query\")+\n",
        "  theme_minimal()+\n",
        "  xlab(\"\")+\n",
        "  ylab(\"tweet count\") \n",
        "\n",
        "# TASK VS TASKS\n",
        "p4 <- query_counts %>% \n",
        "  filter(str_detect(query, \"task\")) %>% \n",
        "  ggplot(aes(x = as.Date(start), y = tweet_count, fill = query)) +\n",
        "  geom_bar(stat = \"identity\", alpha = 0.8, position = \"dodge\") +\n",
        "  scale_fill_brewer(palette = \"Set1\", name = \"Query\")+\n",
        "  theme_minimal()+\n",
        "  xlab(\"\")+\n",
        "  ylab(\"tweet count\") \n",
        "\n",
        "# EMPLOYEE VS EMPLOYEES\n",
        "p5 <- query_counts %>% \n",
        "  filter(str_detect(query, \"employee\")) %>% \n",
        "  ggplot(aes(x = as.Date(start), y = tweet_count, fill = query)) +\n",
        "  geom_bar(stat = \"identity\", alpha = 0.8, position = \"dodge\") +\n",
        "  scale_fill_brewer(palette = \"Set1\", name = \"Query\")+\n",
        "  theme_minimal()+\n",
        "  xlab(\"\")+\n",
        "  ylab(\"tweet count\")\n",
        "\n",
        "library(grid)\n",
        "install.packages(\"gridExtra\")\n",
        "library(gridExtra)\n",
        "grid.arrange(p1, p2, p3, p4, p5, ncol = 1, top = \"Comparing singular and plural\")"
      ],
      "metadata": {
        "id": "ZGF1XKUt8F7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following the analysis above, we can tell that there isn't a clear overlap in the number of tweets returned when searching for singular or plural. Furthermore, while at times searching for a singular word returns more results than the plural equivalent, in other instances the opposite is true.\n",
        "\n",
        "Thus we decided to run a second data collection for the plural form of the words, using the code below.\n",
        "\n",
        "```\n",
        "library(tidyverse)\n",
        "and <- \"chatgpt\"\n",
        "or <- c(\"employees\", # post collection insertion\n",
        "        \"jobs\", # post collection insertion\n",
        "        \"skills\", # post collection insertion\n",
        "        \"concerns\", # post collection insertion\n",
        "        \"threats\", # post collection insertion\n",
        "        \"occupations\", # post collection insertion\n",
        "        \"earnings\", # post collection insertion\n",
        "        \"tasks\", # post collection insertion\n",
        "        \"collaborations\") # post collection insertion\n",
        "\n",
        "queries <- paste(and, or)\n",
        "\n",
        "chatgpt_second_collection <- data.frame()\n",
        "for (i in queries) {\n",
        "  iteration_i <- get_all_tweets(\n",
        "    query = i,\n",
        "    start_tweets = \"2022-11-30T00:00:00Z\",\n",
        "    end_tweets = \"2023-02-24T00:00:00Z\",\n",
        "    n = Inf,\n",
        "    bearer_token = bearer_token,\n",
        "    data_path = \"chatgpt_second_collection/\")\n",
        "  iteration_i$query <- i  # Create a new column \"query\" and assign it the value of i\n",
        "  chatgpt_second_collection <- bind_rows(chatgpt_second_collection, iteration_i)}\n",
        "\n",
        "saveRDS(chatgpt_second_collection, \"chatgpt_second_collection.RDS\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "c4kErsVivrfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Summary statistics and characteristics of the data\n",
        "\n",
        "Upon merging the two datasets, we obtain a total of **548225 tweets**. However, some might be:\n",
        "- duplicates emerging from counting the same tweet more than once in the event it matched more than one keyword in our query string\n",
        "- retweets, which means that different users shared the conversation but essentially there is a repetition in textual content\n",
        "\n",
        "Taking into account the above, we counted that the **unique pieces of text are 191340**. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JC_dqnpsynkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "install.packages(\"jsonlite\") # before installing this package you need to restart the runtime, and then re-run the chunk on R magic\n",
        "library(jsonlite)\n",
        "first_data <- fromJSON(\"/content/chatgpt_employment/full_dataset_chatgpt.json\") # import first collection\n",
        "second_data <- fromJSON(\"/content/chatgpt_employment/second_dataset_chatgpt.json\") # import second collection"
      ],
      "metadata": {
        "id": "WozEryz0ukov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "library(tidyverse) # need to reimport this library since we restarted the runtime\n",
        "tweets <- bind_rows(first_data, second_data, .id = \"id\") # merge datasets\n",
        "nrow(tweets) # number of tweets including duplicates/retweets"
      ],
      "metadata": {
        "id": "zbbeqaKI2qVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# keep only unique observations\n",
        "filtered <- tweets %>%\n",
        "  group_by(text) %>%\n",
        "  slice(1) \n",
        "\n",
        "nrow(filtered) # 191340 is the number of unique tweets across the two datasets"
      ],
      "metadata": {
        "id": "zxlR0xSy3BX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authors\n",
        "\n",
        "How many people partake in the conversation?"
      ],
      "metadata": {
        "id": "11zfjWiU9w1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# how many tweets from the same person have been retweeted?\n",
        "filtered %>% ungroup() %>% select(author_id) %>% drop_na() %>% count(author_id) %>% count(n) %>%\n",
        "mutate(tot_authors = sum(nn),\n",
        "       prop = round(nn/tot_authors*100, 1)) %>%\n",
        "#filter(n < 150) %>%\n",
        "  ggplot(aes(x = n, y = nn)) +\n",
        "  stat_smooth(\n",
        "    geom = 'area', method = 'loess', span = 1/2,\n",
        "    alpha = 0.9, fill = \"lightslateblue\") +\n",
        "  xlab(\"Number of tweets by author\") +\n",
        "  ylab(\"Number of authors\")+\n",
        "  theme_minimal()+\n",
        "  scale_y_log10()+\n",
        "  #scale_x_log10()+\n",
        "  ggtitle(\"Long tail distribution of authors and their tweets\")+\n",
        "  labs(subtitle = \"Most authors publish rarely, but some publish very actively\") "
      ],
      "metadata": {
        "id": "-hcW5BbDy4OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# retweets\n",
        "filtered <- filtered %>%\n",
        "  mutate(rt = str_detect(text, \"RT.*:\\\\s\"))\n",
        "\n",
        "filtered %>% ungroup() %>% count(rt) # 30333 tweets present the RT format, suggesting a retweet"
      ],
      "metadata": {
        "id": "fF3CXL48tDE4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# top tweeters\n",
        "top_tweeters <- filtered %>% ungroup() %>% select(author_id) %>% drop_na() %>% count(author_id, sort = desc(TRUE)) %>% slice_head(n = 3) %>% inner_join(filtered, by = \"author_id\")\n",
        "top_tweeters %>% ungroup() %>% count(rt)  # among top tweeters, around 50% of activity are retweets"
      ],
      "metadata": {
        "id": "DoSjKpZiUaEY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# doing the same for the full dataset\n",
        "tweets <- tweets %>%\n",
        "  mutate(rt = str_detect(text, \"RT.*:\\\\s\"))"
      ],
      "metadata": {
        "id": "NdV95nyvBcFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Timeline\n",
        "\n",
        "How does the discourse look like over time?"
      ],
      "metadata": {
        "id": "gRpzZ5u3AjTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "p1 <- filtered %>% count(created_at) %>% ggplot(aes(x = as.Date(created_at), y = n)) +\n",
        "#geom_bar(stat = \"count\", fill = \"lightslateblue\") +\n",
        "stat_smooth(geom = 'area', method = 'loess', span = 1/2,\n",
        "    alpha = 0.9, fill = \"lightslateblue\") +\n",
        "theme_minimal() +\n",
        "xlab(\"\")\n",
        "\n",
        "p2 <- tweets %>% count(created_at) %>% ggplot(aes(x = as.Date(created_at), y = n)) +\n",
        "#geom_bar(stat = \"count\", fill = \"lightslateblue\") +\n",
        "stat_smooth(geom = 'area', method = 'loess', span = 1/2,\n",
        "    alpha = 0.9, fill = \"lightslateblue\") +\n",
        "theme_minimal() +\n",
        "xlab(\"\")\n",
        "\n",
        "library(gridExtra)\n",
        "grid.arrange(p1, p2, ncol = 1)"
      ],
      "metadata": {
        "id": "tk3tYWYfAqm_",
        "outputId": "76b9fc06-f742-4ef6-fa16-8f40ec516679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`geom_smooth()` using formula = 'y ~ x'\n",
            "`geom_smooth()` using formula = 'y ~ x'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Topic modeling"
      ],
      "metadata": {
        "id": "DH81wQx71AqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# import data\n",
        "df1 = pd.read_json('full_dataset_chatgpt.json', lines=True)\n"
      ],
      "metadata": {
        "id": "MGs-wMIK26iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model type one: BERTopic"
      ],
      "metadata": {
        "id": "IyImnXBn1Djw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sVj_XGEt1dWw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model type two: Gensim "
      ],
      "metadata": {
        "id": "lzlZ_id01IQg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wzXAAoH61PBe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model type three: LDA"
      ],
      "metadata": {
        "id": "rSE9lEbN20xI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7b9f0yaS25CA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}